{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e55223",
   "metadata": {},
   "source": [
    "# Translation API `v0.0.1` Examples\n",
    "\n",
    "This notebook uses the `requests` library to interact with a previously-deployed translation API service. It demonstrates how to send text data for translation and receive the translated output.\n",
    "\n",
    "This exploration can alternatively be done on a web browser using the automatically-generated Swagger UI documentation available at the `/docs` endpoint of the deployed API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cec0af",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Root Endpoint](#1.-Root-Endpoint)\n",
    "2. [Health Endpoint](#2.-Health-Endpoint)\n",
    "3. [Models Endpoint](#3.-Models-Endpoint)\n",
    "   - [3.1 Basic response](#3.1-Basic-response)\n",
    "   - [3.2 Detailed response](#3.2-Detailed-response)\n",
    "4. [Prediction Endpoint](#4.-Prediction-Endpoint)\n",
    "   - [4.1 Single Translation with pre-loaded model and basic parameters](#4.1-Single-Translation-with-pre-loaded-model-and-basic-parameters)\n",
    "   - [4.2 Single Translation with model downloading and basic parameters](#4.2-Single-Translation-with-model-downloading-and-basic-parameters)\n",
    "   - [4.3 Sending Multiple Items at once](#4.3-Sending-Multiple-Items-at-once)\n",
    "   - [4.4 Single Translation with advanced parameters](#4.4-Single-Translation-with-advanced-parameters)\n",
    "   - [4.5 Endpoint failure case](#4.5-Endpoint-failure-case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95365420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get required libraries\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# define constants\n",
    "base_api_url = 'http://0.0.0.0:8000/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f78482",
   "metadata": {},
   "source": [
    "## 1. Root Endpoint\n",
    "\n",
    "The root endpoint (`/`) provides basic information about the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a9ff862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.006\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"name\": \"Translation API\",\n",
      "    \"version\": \"v0.0.1\",\n",
      "    \"description\": \"API for text translation using pre-trained Transformer models.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = requests.get(base_api_url)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380e542",
   "metadata": {},
   "source": [
    "## 2. Health Endpoint\n",
    "\n",
    "The health endpoint (`/health`) returns a simple response to check the API is up and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b5b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.006\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"status\": \"ok\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "health_url = base_api_url + 'health'\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.get(health_url)\n",
    "end_time = time.time()\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfe730",
   "metadata": {},
   "source": [
    "## 3. Models Endpoint\n",
    "\n",
    "From here on, things get more interesting. The `/models` endpoint allows you to check on the translation models that are currently available (downloaded and enabled) in the API for each translation pair.\n",
    "\n",
    "This endpoint includes an optional query parameter, `return_model_config`, which when set to `true` will return additional metadata about each model from its configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc5cc8",
   "metadata": {},
   "source": [
    "### 3.1 Basic response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5f167aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.009\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"models\": {\n",
      "        \"en-fr\": {\n",
      "            \"model_name\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
      "            \"file_type\": \"ONNX\",\n",
      "            \"config\": null\n",
      "        },\n",
      "        \"en-es\": {\n",
      "            \"model_name\": \"Helsinki-NLP/opus-mt-en-es\",\n",
      "            \"file_type\": \"ONNX\",\n",
      "            \"config\": null\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "return_model_config = False\n",
    "models_url = base_api_url + 'models' + ('?return_model_config=true' if return_model_config else '')\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.get(models_url)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744561f5",
   "metadata": {},
   "source": [
    "The basic response returns for each translation pair:\n",
    "* Hugging Face model name\n",
    "* Storage file type, which is always \"ONNX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41183ff8",
   "metadata": {},
   "source": [
    "### 3.2 Detailed response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f756d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.008\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"models\": {\n",
      "        \"en-fr\": {\n",
      "            \"model_name\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
      "            \"file_type\": \"ONNX\",\n",
      "            \"config\": {\n",
      "                \"_num_labels\": 3,\n",
      "                \"activation_dropout\": 0.0,\n",
      "                \"activation_function\": \"swish\",\n",
      "                \"add_bias_logits\": false,\n",
      "                \"add_final_layer_norm\": false,\n",
      "                \"architectures\": [\n",
      "                    \"MarianMTModel\"\n",
      "                ],\n",
      "                \"attention_dropout\": 0.0,\n",
      "                \"bos_token_id\": 0,\n",
      "                \"classif_dropout\": 0.0,\n",
      "                \"classifier_dropout\": 0.0,\n",
      "                \"d_model\": 512,\n",
      "                \"decoder_attention_heads\": 8,\n",
      "                \"decoder_ffn_dim\": 2048,\n",
      "                \"decoder_layerdrop\": 0.0,\n",
      "                \"decoder_layers\": 6,\n",
      "                \"decoder_start_token_id\": 59513,\n",
      "                \"decoder_vocab_size\": 59514,\n",
      "                \"dropout\": 0.1,\n",
      "                \"encoder_attention_heads\": 8,\n",
      "                \"encoder_ffn_dim\": 2048,\n",
      "                \"encoder_layerdrop\": 0.0,\n",
      "                \"encoder_layers\": 6,\n",
      "                \"eos_token_id\": 0,\n",
      "                \"forced_eos_token_id\": 0,\n",
      "                \"gradient_checkpointing\": false,\n",
      "                \"id2label\": {\n",
      "                    \"0\": \"LABEL_0\",\n",
      "                    \"1\": \"LABEL_1\",\n",
      "                    \"2\": \"LABEL_2\"\n",
      "                },\n",
      "                \"init_std\": 0.02,\n",
      "                \"is_encoder_decoder\": true,\n",
      "                \"label2id\": {\n",
      "                    \"LABEL_0\": 0,\n",
      "                    \"LABEL_1\": 1,\n",
      "                    \"LABEL_2\": 2\n",
      "                },\n",
      "                \"max_length\": null,\n",
      "                \"max_position_embeddings\": 512,\n",
      "                \"model_type\": \"marian\",\n",
      "                \"normalize_before\": false,\n",
      "                \"normalize_embedding\": false,\n",
      "                \"num_beams\": null,\n",
      "                \"num_hidden_layers\": 6,\n",
      "                \"pad_token_id\": 59513,\n",
      "                \"scale_embedding\": true,\n",
      "                \"share_encoder_decoder_embeddings\": true,\n",
      "                \"static_position_embeddings\": true,\n",
      "                \"transformers_version\": \"4.55.4\",\n",
      "                \"use_cache\": true,\n",
      "                \"vocab_size\": 59514\n",
      "            }\n",
      "        },\n",
      "        \"en-es\": {\n",
      "            \"model_name\": \"Helsinki-NLP/opus-mt-en-es\",\n",
      "            \"file_type\": \"ONNX\",\n",
      "            \"config\": {\n",
      "                \"activation_dropout\": 0.0,\n",
      "                \"activation_function\": \"swish\",\n",
      "                \"add_bias_logits\": false,\n",
      "                \"add_final_layer_norm\": false,\n",
      "                \"architectures\": [\n",
      "                    \"MarianMTModel\"\n",
      "                ],\n",
      "                \"attention_dropout\": 0.0,\n",
      "                \"bos_token_id\": 0,\n",
      "                \"classif_dropout\": 0.0,\n",
      "                \"classifier_dropout\": 0.0,\n",
      "                \"d_model\": 512,\n",
      "                \"decoder_attention_heads\": 8,\n",
      "                \"decoder_ffn_dim\": 2048,\n",
      "                \"decoder_layerdrop\": 0.0,\n",
      "                \"decoder_layers\": 6,\n",
      "                \"decoder_start_token_id\": 65000,\n",
      "                \"decoder_vocab_size\": 65001,\n",
      "                \"dropout\": 0.1,\n",
      "                \"encoder_attention_heads\": 8,\n",
      "                \"encoder_ffn_dim\": 2048,\n",
      "                \"encoder_layerdrop\": 0.0,\n",
      "                \"encoder_layers\": 6,\n",
      "                \"eos_token_id\": 0,\n",
      "                \"extra_pos_embeddings\": 65001,\n",
      "                \"force_bos_token_to_be_generated\": false,\n",
      "                \"forced_eos_token_id\": 0,\n",
      "                \"gradient_checkpointing\": false,\n",
      "                \"id2label\": {\n",
      "                    \"0\": \"LABEL_0\",\n",
      "                    \"1\": \"LABEL_1\",\n",
      "                    \"2\": \"LABEL_2\"\n",
      "                },\n",
      "                \"init_std\": 0.02,\n",
      "                \"is_encoder_decoder\": true,\n",
      "                \"label2id\": {\n",
      "                    \"LABEL_0\": 0,\n",
      "                    \"LABEL_1\": 1,\n",
      "                    \"LABEL_2\": 2\n",
      "                },\n",
      "                \"max_length\": null,\n",
      "                \"max_position_embeddings\": 512,\n",
      "                \"model_type\": \"marian\",\n",
      "                \"normalize_before\": false,\n",
      "                \"normalize_embedding\": false,\n",
      "                \"num_beams\": null,\n",
      "                \"num_hidden_layers\": 6,\n",
      "                \"pad_token_id\": 65000,\n",
      "                \"scale_embedding\": true,\n",
      "                \"share_encoder_decoder_embeddings\": true,\n",
      "                \"static_position_embeddings\": true,\n",
      "                \"transformers_version\": \"4.55.4\",\n",
      "                \"use_cache\": true,\n",
      "                \"vocab_size\": 65001\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "return_model_config = True\n",
    "models_url = base_api_url + 'models' + ('?return_model_config=true' if return_model_config else '')\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.get(models_url)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f543f",
   "metadata": {},
   "source": [
    "In addition to the elements in the basic response, the detailed response includes a `config` key, which contains the full model configuration as specified in the model's configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632abc59",
   "metadata": {},
   "source": [
    "## 4. Prediction Endpoint\n",
    "\n",
    "The prediction endpoint is the core functionality of the API. It allows you to send text data for translation and receive the translated output.\n",
    "\n",
    "In contrast to the previous endpoints, this one requires a POST request with a JSON payload containing the text to be translated and the desired translation pair, among other optional parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3488f8e",
   "metadata": {},
   "source": [
    "By default, before initializing the API service some of the models available for translation will be pre-emptively downloaded locally so they may be used quickly, but not all of them, in order to conserve volume space. This behavior can be controlled using the `STARTUP_MODEL_LOADING_LIMIT` variable in `config.py`.\n",
    "\n",
    "in this case, the value was set to 2, which means the models for the first two translation pairs within `AVAILABLE_TRANSLATIONS`, 'en-fr' and 'en-es', were downloaded before starting the API service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ba0908",
   "metadata": {},
   "source": [
    "### 4.1 Single Translation with pre-loaded model and basic parameters\n",
    "\n",
    "This first example shows how to perform a single translation to a pre-loaded model using only the required parameters: `source`, `target`, and `text`.\n",
    "\n",
    "The first request should take longer than subsequent requests, because although the model is already downloaded, it still needs to be loaded into memory for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313b41d",
   "metadata": {},
   "source": [
    "First request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3845e811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 1.56\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"position\": 0,\n",
      "            \"result\": \"Le gar\\u00e7on aux cheveux justes s'est abaiss\\u00e9 dans les derniers pieds de terre rocheuse et a commenc\\u00e9 \\u00e0 prendre son chemin vers la lagune.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prediction_url = base_api_url + 'predict'\n",
    "\n",
    "payload = {\n",
    "    \"items\": [{\n",
    "        \"source\": \"en\",\n",
    "        \"target\": \"fr\",\n",
    "        \"text\": \"The boy with fair hair lowered himself down in the last few feet of rocky ground and began to pick his way toward the lagoon.\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(prediction_url, json=payload)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f2d4f",
   "metadata": {},
   "source": [
    "Second request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d04c1c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.413\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"position\": 0,\n",
      "            \"result\": \"Ralph pagaie \\u00e0 l'envers sur la pente, plonge sa bouche et souffle un jet d'eau dans l'air.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prediction_url = base_api_url + 'predict'\n",
    "\n",
    "payload = {\n",
    "    \"items\": [{\n",
    "        \"source\": \"en\",\n",
    "        \"target\": \"fr\",\n",
    "        \"text\": \"Ralph paddled backwards down the slope, immersed his mouth, and blew a jet of water into the air.\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(prediction_url, json=payload)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1406d83",
   "metadata": {},
   "source": [
    "### 4.2 Single Translation with model downloading and basic parameters\n",
    "\n",
    "In this example, a translation request will be made to a model that isn't yet loaded. Latency for the first request should be very high as the model is being downloaded and then loaded into memory for inference, and should drop for subsequent requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a2a87",
   "metadata": {},
   "source": [
    "First request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05015e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 20.938\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"position\": 0,\n",
      "            \"result\": \"Es entstand ein Sturm des Lachens und sogar das kleinste Kind schloss sich an.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"items\": [{\n",
    "        \"source\": \"en\",\n",
    "        \"target\": \"de\",\n",
    "        \"text\": \"A storm of laughter arose and even the tiniest child joined in.\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(prediction_url, json=payload)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494a752",
   "metadata": {},
   "source": [
    "Second request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0c693b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.322\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"position\": 0,\n",
      "            \"result\": \"Du bist in so einem Job nicht gut.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"items\": [{\n",
    "        \"source\": \"en\",\n",
    "        \"target\": \"de\",\n",
    "        \"text\": \"You're no good on a job like this.\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(prediction_url, json=payload)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb6336f",
   "metadata": {},
   "source": [
    "### 4.3 Sending Multiple Items at once\n",
    "\n",
    "The API also supports sending more than one item to be translated in a single request in different languages. This is done by including multiple items in the `items` list of the JSON payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22e071b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.512\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"position\": 0,\n",
      "            \"result\": \"El primer ritmo al que se acostumbraron fue el lento balanceo del amanecer al atardecer r\\u00e1pido.\"\n",
      "        },\n",
      "        {\n",
      "            \"position\": 1,\n",
      "            \"result\": \"Mantenga el fuego encendido.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"items\": [\n",
    "        {\n",
    "            \"source\": \"fr\",\n",
    "            \"target\": \"es\",\n",
    "            \"text\": \"Le premier rythme auquel ils s'habituèrent fut le lent balancement de l'aube au crépuscule rapide.\"\n",
    "        },\n",
    "        {\n",
    "            \"source\": \"en\",\n",
    "            \"target\": \"es\",\n",
    "            \"text\": \"Keep the fire going.\"\n",
    "        },\n",
    "        {\n",
    "            \"source\": \"es\",\n",
    "            \"target\": \"de\",\n",
    "            \"text\": \"¡No existe la bestia!\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(prediction_url, json=payload)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b8854",
   "metadata": {},
   "source": [
    "The translation pair for the third item, `es-de`, wasn't included in the original `AVAILABLE_TRANSLATIONS` list, so the individual request failed and the translation wasn't included in the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19b9fb",
   "metadata": {},
   "source": [
    "### 4.4 Single Translation with advanced parameters\n",
    "\n",
    "Lastly, the API supports advanced parameters to pass onto the translation model, which is ultimately a transformer-type neural network. These parameters are:\n",
    "* `max_length`: Maximum length of the generated translation (in tokens).\n",
    "* `num_beams`: Number of beams for beam search, aka the number of parallel hypotheses to consider during decoding. At the end, the beam (sequence) with the highest overall probability is selected as the final output.\n",
    "* `early_stopping`: Whether to stop the beam search when at least `num_beams` sentences are finished per batch item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cdbf5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.51\n",
      "Response status code: 200\n",
      "Response content: {\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"position\": 0,\n",
      "            \"result\": \"Tal vez hay una bestia, lo que quiero decir es... tal vez s\\u00f3lo somos nosotros.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"items\": [{\n",
    "        \"source\": \"en\",\n",
    "        \"target\": \"es\",\n",
    "        \"text\": \"Maybe there is a beast, what I mean is... maybe it's only us.\",\n",
    "        \"max_length\": 200,\n",
    "        \"num_beams\": 10,\n",
    "        \"early_stopping\": True\n",
    "    }]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(prediction_url, json=payload)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3e9c1",
   "metadata": {},
   "source": [
    "### 4.5 Endpoint failure case\n",
    "\n",
    "The API will return a 500 error if all of the translation requests within the batch failed without breaking the application. In this case, the response failed because the translation pair `en-pt` is not included in the `AVAILABLE_TRANSLATIONS` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2f3615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request time (s): 0.012\n",
      "Response status code: 500\n",
      "Response content: {\n",
      "    \"detail\": \"All translation attempts failed.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"items\": [{\n",
    "        \"source\": \"en\",\n",
    "        \"target\": \"pt\",\n",
    "        \"text\": \"Maybe there is a beast, what I mean is... maybe it's only us.\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(prediction_url, json=payload)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Request time (s):\", round(end_time - start_time, 3))\n",
    "print(\"Response status code:\", response.status_code)\n",
    "try:\n",
    "    content = json.loads(response.content)\n",
    "    print(\"Response content:\", json.dumps(content, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response content is not valid JSON:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
